cuda memory allocated: 499917824
> n_trainable_params: 124653442, n_nontrainable_params: 0
> training arguments:
>>> model_name: ROBERTA_CRF
>>> dataset: small
>>> optimizer: <class 'torch.optim.adamw.AdamW'>
>>> initializer: <function kaiming_uniform_ at 0x000002D20912A3B0>
>>> lr: 2e-05
>>> dropout: 0.1
>>> l2reg: 1e-05
>>> epochs: 5
>>> batch_size: 16
>>> log_step: 10
>>> max_seq_len: 512
>>> device: cuda
>>> seed: 42
>>> valset_ratio: 0.0
>>> model_class: <class 'models.roberta_crf.ROBERTA_CRF'>
>>> dataset_file: {'train': 'dataset/train_small.txt', 'test': 'dataset/test.txt'}
>>> bert_config_path: ../../../pretrained/BertConfig/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594
>>> bert_model_path: ../../../pretrained/BertModel/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b
>>> bert_tokenizer_path: ../../../pretrained/BertTokenizer/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b
>>> roberta_config_path: ../../../pretrained/RobertaConfig/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b
>>> roberta_model_path: ../../../pretrained/RobertaModel/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b
>>> roberta_tokenizer_path: ../../../pretrained/RobertaTokenizer/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b
>>> tokenizer: RobertaTokenizer(name_or_path='../../../pretrained/RobertaTokenizer/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b', vocab_size=50265, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={
	0: AddedToken("<s>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
	1: AddedToken("<pad>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
	2: AddedToken("</s>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
	3: AddedToken("<unk>", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),
	50264: AddedToken("<mask>", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),
}
>>> target_size: 10
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 28.4781, f1: 0.4395
loss: 20.9292, f1: 0.6136
loss: 17.3616, f1: 0.6774
loss: 15.0079, f1: 0.7183
loss: 13.1783, f1: 0.7494
loss: 11.7677, f1: 0.7706
loss: 10.8663, f1: 0.7890
loss: 10.0946, f1: 0.8007
loss: 9.4661, f1: 0.8125
> val_f1: 0.9058
>> saved: state_dict/ROBERTA_CRF_small_val_f1_0.9058
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 3.7554, f1: 0.9183
loss: 3.5643, f1: 0.9180
loss: 3.3109, f1: 0.9226
loss: 3.3910, f1: 0.9230
loss: 3.3199, f1: 0.9251
loss: 3.2770, f1: 0.9268
loss: 3.2933, f1: 0.9261
loss: 3.3199, f1: 0.9276
loss: 3.2389, f1: 0.9295
> val_f1: 0.9260
>> saved: state_dict/ROBERTA_CRF_small_val_f1_0.926
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 2.5341, f1: 0.9426
loss: 2.2332, f1: 0.9463
loss: 2.2647, f1: 0.9485
loss: 2.2177, f1: 0.9504
loss: 2.2592, f1: 0.9493
loss: 2.1626, f1: 0.9514
loss: 2.1421, f1: 0.9516
loss: 2.1295, f1: 0.9523
loss: 2.1061, f1: 0.9528
> val_f1: 0.9387
>> saved: state_dict/ROBERTA_CRF_small_val_f1_0.9387
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 1.3034, f1: 0.9715
loss: 1.6389, f1: 0.9632
loss: 1.5975, f1: 0.9642
loss: 1.5648, f1: 0.9658
loss: 1.5609, f1: 0.9648
loss: 1.5480, f1: 0.9659
loss: 1.5847, f1: 0.9646
loss: 1.5441, f1: 0.9650
loss: 1.5333, f1: 0.9659
> val_f1: 0.9441
>> saved: state_dict/ROBERTA_CRF_small_val_f1_0.9441
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 1.2300, f1: 0.9713
loss: 1.1670, f1: 0.9740
loss: 1.1424, f1: 0.9756
loss: 1.0791, f1: 0.9776
loss: 1.0142, f1: 0.9782
loss: 1.0234, f1: 0.9777
loss: 1.0310, f1: 0.9775
loss: 1.0360, f1: 0.9770
loss: 1.0571, f1: 0.9759
> val_f1: 0.9459
>> saved: state_dict/ROBERTA_CRF_small_val_f1_0.9459
>> test_f1: 0.9459
