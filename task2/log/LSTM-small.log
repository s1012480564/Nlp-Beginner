cuda memory allocated: 5828608
> n_trainable_params: 1447805, n_nontrainable_params: 9000
> training arguments:
>>> model_name: LSTM
>>> dataset: small
>>> optimizer: <class 'torch.optim.adamw.AdamW'>
>>> initializer: <function kaiming_uniform_ at 0x00000164DC1C0040>
>>> lr: 0.001
>>> dropout: 0.1
>>> l2reg: 0.01
>>> epochs: 5
>>> batch_size: 50
>>> log_step: 10
>>> embed_dim: 300
>>> hidden_dim: 300
>>> bert_dim: 768
>>> kernel_sizes: [3, 4, 5]
>>> kernel_num: 100
>>> max_seq_len: 85
>>> num_classes: 5
>>> device: cuda
>>> seed: 42
>>> valset_ratio: 0.2
>>> model_class: <class 'task2.models.lstm.LSTM'>
>>> dataset_file: {'train': 'dataset/train_small.csv', 'test': 'dataset/test.csv'}
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
cuda memory allocated: 5828608
> n_trainable_params: 1447805, n_nontrainable_params: 9000
> training arguments:
>>> model_name: LSTM
>>> dataset: small
>>> optimizer: <class 'torch.optim.adamw.AdamW'>
>>> initializer: <function kaiming_uniform_ at 0x0000024218070040>
>>> lr: 0.001
>>> dropout: 0.1
>>> l2reg: 0.01
>>> epochs: 5
>>> batch_size: 50
>>> log_step: 10
>>> embed_dim: 300
>>> hidden_dim: 300
>>> bert_dim: 768
>>> kernel_sizes: [3, 4, 5]
>>> kernel_num: 100
>>> pretrained_bert_name: bert-base-uncased
>>> max_seq_len: 85
>>> num_classes: 5
>>> device: cuda
>>> seed: 42
>>> valset_ratio: 0.2
>>> model_class: <class 'task2.models.lstm.LSTM'>
>>> dataset_file: {'train': 'dataset/train_small.csv', 'test': 'dataset/test.csv'}
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
cuda memory allocated: 5828608
> n_trainable_params: 1447805, n_nontrainable_params: 9000
> training arguments:
>>> model_name: LSTM
>>> dataset: small
>>> optimizer: <class 'torch.optim.adamw.AdamW'>
>>> initializer: <function kaiming_uniform_ at 0x00000249EC420040>
>>> lr: 0.001
>>> dropout: 0.1
>>> l2reg: 0.01
>>> epochs: 5
>>> batch_size: 50
>>> log_step: 10
>>> embed_dim: 300
>>> hidden_dim: 300
>>> bert_dim: 768
>>> kernel_sizes: [3, 4, 5]
>>> kernel_num: 100
>>> pretrained_bert_name: bert-base-uncased
>>> max_seq_len: 85
>>> num_classes: 5
>>> device: cuda
>>> seed: 42
>>> valset_ratio: 0.2
>>> model_class: <class 'task2.models.lstm.LSTM'>
>>> dataset_file: {'train': 'dataset/train_small.csv', 'test': 'dataset/test.csv'}
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 1.5515, acc: 0.2260
> val_acc: 0.3700, val_f1: 0.1722
>> saved: state_dict/LSTM_small_val_acc_0.37
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 1.3787, acc: 0.3600
loss: 1.2822, acc: 0.4429
> val_acc: 0.7100, val_f1: 0.2069
>> saved: state_dict/LSTM_small_val_acc_0.71
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 1.1562, acc: 0.7025
> val_acc: 0.7150, val_f1: 0.2238
>> saved: state_dict/LSTM_small_val_acc_0.715
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 1.1456, acc: 0.6200
loss: 1.0381, acc: 0.6717
> val_acc: 0.7100, val_f1: 0.2673
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.8964, acc: 0.7167
loss: 0.9191, acc: 0.7087
> val_acc: 0.7000, val_f1: 0.2970
cuda memory allocated: 6244864
> n_trainable_params: 1447805, n_nontrainable_params: 113100
> training arguments:
>>> model_name: LSTM
>>> dataset: small
>>> optimizer: <class 'torch.optim.adamw.AdamW'>
>>> initializer: <function kaiming_uniform_ at 0x000002534CECBF40>
>>> lr: 0.001
>>> dropout: 0.1
>>> l2reg: 0.01
>>> epochs: 5
>>> batch_size: 50
>>> log_step: 10
>>> embed_dim: 300
>>> hidden_dim: 300
>>> bert_dim: 768
>>> kernel_sizes: [3, 4, 5]
>>> kernel_num: 100
>>> max_seq_len: 85
>>> num_classes: 5
>>> device: cuda
>>> seed: 42
>>> valset_ratio: 0.2
>>> model_class: <class 'task2.models.lstm.LSTM'>
>>> dataset_file: {'train': 'dataset/train_small.csv', 'test': 'dataset/test.csv'}
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 1.3651, acc: 0.4600
> val_acc: 0.6800, val_f1: 0.3097
>> saved: state_dict/LSTM_small_val_acc_0.68
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.9873, acc: 0.6200
loss: 0.9109, acc: 0.6429
> val_acc: 0.7150, val_f1: 0.3736
>> saved: state_dict/LSTM_small_val_acc_0.715
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.7156, acc: 0.7425
> val_acc: 0.7350, val_f1: 0.3439
>> saved: state_dict/LSTM_small_val_acc_0.735
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.7290, acc: 0.7400
loss: 0.6057, acc: 0.7983
> val_acc: 0.7400, val_f1: 0.3862
>> saved: state_dict/LSTM_small_val_acc_0.74
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.4820, acc: 0.8433
loss: 0.4800, acc: 0.8488
> val_acc: 0.7350, val_f1: 0.3796
cuda memory allocated: 6244864
> n_trainable_params: 1447805, n_nontrainable_params: 113100
> training arguments:
>>> model_name: LSTM
>>> dataset: small
>>> optimizer: <class 'torch.optim.adamw.AdamW'>
>>> initializer: <function kaiming_uniform_ at 0x0000027BD3BCBF40>
>>> lr: 0.001
>>> dropout: 0.1
>>> l2reg: 0.01
>>> epochs: 5
>>> batch_size: 50
>>> log_step: 10
>>> embed_dim: 300
>>> hidden_dim: 300
>>> bert_dim: 768
>>> kernel_sizes: [3, 4, 5]
>>> kernel_num: 100
>>> max_seq_len: 85
>>> num_classes: 5
>>> device: cuda
>>> seed: 42
>>> valset_ratio: 0.2
>>> model_class: <class 'models.lstm.LSTM'>
>>> dataset_file: {'train': 'dataset/train_small.csv', 'test': 'dataset/test.csv'}
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 1.3651, acc: 0.4600
> val_acc: 0.6800, val_f1: 0.3097
>> saved: state_dict/LSTM_small_val_acc_0.68
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.9873, acc: 0.6200
loss: 0.9109, acc: 0.6429
> val_acc: 0.7150, val_f1: 0.3736
>> saved: state_dict/LSTM_small_val_acc_0.715
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.7156, acc: 0.7425
> val_acc: 0.7350, val_f1: 0.3439
>> saved: state_dict/LSTM_small_val_acc_0.735
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.7290, acc: 0.7400
loss: 0.6057, acc: 0.7983
> val_acc: 0.7400, val_f1: 0.3862
>> saved: state_dict/LSTM_small_val_acc_0.74
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.4820, acc: 0.8433
loss: 0.4800, acc: 0.8488
> val_acc: 0.7350, val_f1: 0.3796
cuda memory allocated: 6244864
> n_trainable_params: 1447805, n_nontrainable_params: 113100
> training arguments:
>>> model_name: LSTM
>>> dataset: small
>>> optimizer: <class 'torch.optim.adamw.AdamW'>
>>> initializer: <function kaiming_uniform_ at 0x000001971A61BF40>
>>> lr: 0.001
>>> dropout: 0.1
>>> l2reg: 0.01
>>> epochs: 5
>>> batch_size: 50
>>> log_step: 10
>>> embed_dim: 300
>>> hidden_dim: 300
>>> bert_dim: 768
>>> kernel_sizes: [3, 4, 5]
>>> kernel_num: 100
>>> max_seq_len: 85
>>> num_classes: 5
>>> device: cuda
>>> seed: 42
>>> valset_ratio: 0.2
>>> model_class: <class 'models.lstm.LSTM'>
>>> dataset_file: {'train': 'dataset/train_small.csv', 'test': 'dataset/test.csv'}
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 1.3651, acc: 0.4600
> val_acc: 0.6800, val_f1: 0.3097
>> saved: state_dict/LSTM_small_val_acc_0.68
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.9873, acc: 0.6200
loss: 0.9109, acc: 0.6429
> val_acc: 0.7150, val_f1: 0.3736
>> saved: state_dict/LSTM_small_val_acc_0.715
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.7156, acc: 0.7425
> val_acc: 0.7350, val_f1: 0.3439
>> saved: state_dict/LSTM_small_val_acc_0.735
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.7290, acc: 0.7400
loss: 0.6057, acc: 0.7983
> val_acc: 0.7400, val_f1: 0.3862
>> saved: state_dict/LSTM_small_val_acc_0.74
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.4820, acc: 0.8433
loss: 0.4800, acc: 0.8488
> val_acc: 0.7350, val_f1: 0.3796
