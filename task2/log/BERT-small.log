cuda memory allocated: 439085568
> n_trainable_params: 109486085, n_nontrainable_params: 0
> training arguments:
>>> model_name: BERT
>>> dataset: small
>>> optimizer: <class 'torch.optim.adamw.AdamW'>
>>> initializer: <function kaiming_uniform_ at 0x0000023B081AE0E0>
>>> lr: 2e-05
>>> dropout: 0.1
>>> l2reg: 1e-05
>>> epochs: 5
>>> batch_size: 32
>>> log_step: 10
>>> max_seq_len: 512
>>> num_classes: 5
>>> device: cuda
>>> seed: 42
>>> valset_ratio: 0.2
>>> model_class: <class 'models.bert.BERT'>
>>> dataset_file: {'train': 'dataset/train_small.csv', 'test': 'dataset/test.csv'}
>>> bert_config_path: ../../../pretrained/BertConfig/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594
>>> bert_model_path: ../../../pretrained/BertModel/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b
>>> bert_tokenizer_path: ../../../pretrained/BertTokenizer/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b
>>> tokenizer: BertTokenizer(name_or_path='../../../pretrained/BertTokenizer/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b', vocab_size=30522, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={
	0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	100: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	101: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	102: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	103: AddedToken("[MASK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 1.3665, acc: 0.5188
loss: 1.3195, acc: 0.5328
loss: 1.2467, acc: 0.5573
loss: 1.2161, acc: 0.5617
loss: 1.1967, acc: 0.5656
loss: 1.1622, acc: 0.5755
loss: 1.1417, acc: 0.5795
loss: 1.1183, acc: 0.5879
loss: 1.1017, acc: 0.5927
loss: 1.0804, acc: 0.5966
loss: 1.0619, acc: 0.6020
loss: 1.0469, acc: 0.6062
loss: 1.0295, acc: 0.6139
loss: 1.0171, acc: 0.6170
loss: 1.0032, acc: 0.6221
loss: 0.9878, acc: 0.6258
loss: 0.9787, acc: 0.6267
loss: 0.9706, acc: 0.6311
loss: 0.9651, acc: 0.6322
loss: 0.9531, acc: 0.6355
loss: 0.9468, acc: 0.6382
loss: 0.9439, acc: 0.6405
loss: 0.9405, acc: 0.6410
loss: 0.9321, acc: 0.6441
loss: 0.9264, acc: 0.6458
loss: 0.9220, acc: 0.6476
loss: 0.9208, acc: 0.6470
loss: 0.9167, acc: 0.6487
loss: 0.9128, acc: 0.6497
loss: 0.9089, acc: 0.6498
loss: 0.9061, acc: 0.6500
loss: 0.9023, acc: 0.6512
loss: 0.9005, acc: 0.6511
loss: 0.8969, acc: 0.6525
loss: 0.8950, acc: 0.6519
loss: 0.8924, acc: 0.6510
loss: 0.8904, acc: 0.6513
loss: 0.8853, acc: 0.6522
loss: 0.8829, acc: 0.6533
> val_acc: 0.6908, val_f1: 0.5450
>> saved: state_dict/BERT_small_val_acc_0.6908
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 0.6891, acc: 0.7431
loss: 0.6589, acc: 0.7401
loss: 0.6354, acc: 0.7511
loss: 0.6415, acc: 0.7428
loss: 0.6452, acc: 0.7411
loss: 0.6373, acc: 0.7452
loss: 0.6396, acc: 0.7396
loss: 0.6413, acc: 0.7350
loss: 0.6448, acc: 0.7349
loss: 0.6512, acc: 0.7317
loss: 0.6454, acc: 0.7348
loss: 0.6473, acc: 0.7345
loss: 0.6485, acc: 0.7350
loss: 0.6477, acc: 0.7349
loss: 0.6463, acc: 0.7362
loss: 0.6503, acc: 0.7347
loss: 0.6495, acc: 0.7369
loss: 0.6443, acc: 0.7374
loss: 0.6426, acc: 0.7374
loss: 0.6437, acc: 0.7368
loss: 0.6446, acc: 0.7371
loss: 0.6460, acc: 0.7359
loss: 0.6465, acc: 0.7361
loss: 0.6474, acc: 0.7368
loss: 0.6496, acc: 0.7368
loss: 0.6497, acc: 0.7371
loss: 0.6527, acc: 0.7366
loss: 0.6526, acc: 0.7362
loss: 0.6530, acc: 0.7365
loss: 0.6507, acc: 0.7374
loss: 0.6529, acc: 0.7350
loss: 0.6537, acc: 0.7339
loss: 0.6560, acc: 0.7327
loss: 0.6579, acc: 0.7314
loss: 0.6592, acc: 0.7313
loss: 0.6596, acc: 0.7315
loss: 0.6625, acc: 0.7306
loss: 0.6602, acc: 0.7315
loss: 0.6605, acc: 0.7316
> val_acc: 0.7007, val_f1: 0.5634
>> saved: state_dict/BERT_small_val_acc_0.7007
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 0.5426, acc: 0.7930
loss: 0.5390, acc: 0.7674
loss: 0.5317, acc: 0.7879
loss: 0.5228, acc: 0.7854
loss: 0.5190, acc: 0.7826
loss: 0.5273, acc: 0.7807
loss: 0.5343, acc: 0.7785
loss: 0.5353, acc: 0.7796
loss: 0.5443, acc: 0.7745
loss: 0.5394, acc: 0.7774
loss: 0.5418, acc: 0.7769
loss: 0.5382, acc: 0.7799
loss: 0.5407, acc: 0.7798
loss: 0.5370, acc: 0.7826
loss: 0.5396, acc: 0.7812
loss: 0.5424, acc: 0.7791
loss: 0.5377, acc: 0.7814
loss: 0.5362, acc: 0.7823
loss: 0.5345, acc: 0.7824
loss: 0.5357, acc: 0.7828
loss: 0.5377, acc: 0.7812
loss: 0.5389, acc: 0.7810
loss: 0.5388, acc: 0.7812
loss: 0.5388, acc: 0.7814
loss: 0.5404, acc: 0.7805
loss: 0.5395, acc: 0.7804
loss: 0.5413, acc: 0.7793
loss: 0.5414, acc: 0.7792
loss: 0.5401, acc: 0.7797
loss: 0.5395, acc: 0.7805
loss: 0.5416, acc: 0.7795
loss: 0.5438, acc: 0.7788
loss: 0.5457, acc: 0.7770
loss: 0.5464, acc: 0.7776
loss: 0.5470, acc: 0.7769
loss: 0.5468, acc: 0.7775
loss: 0.5485, acc: 0.7767
loss: 0.5496, acc: 0.7763
loss: 0.5498, acc: 0.7766
> val_acc: 0.6873, val_f1: 0.5709
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 0.3900, acc: 0.8661
loss: 0.3910, acc: 0.8603
loss: 0.4206, acc: 0.8322
loss: 0.4395, acc: 0.8243
loss: 0.4368, acc: 0.8258
loss: 0.4383, acc: 0.8218
loss: 0.4540, acc: 0.8181
loss: 0.4570, acc: 0.8178
loss: 0.4499, acc: 0.8200
loss: 0.4552, acc: 0.8170
loss: 0.4511, acc: 0.8180
loss: 0.4511, acc: 0.8192
loss: 0.4543, acc: 0.8187
loss: 0.4509, acc: 0.8212
loss: 0.4527, acc: 0.8195
loss: 0.4513, acc: 0.8195
loss: 0.4471, acc: 0.8211
loss: 0.4489, acc: 0.8197
loss: 0.4459, acc: 0.8207
loss: 0.4472, acc: 0.8195
loss: 0.4540, acc: 0.8172
loss: 0.4540, acc: 0.8167
loss: 0.4557, acc: 0.8154
loss: 0.4556, acc: 0.8146
loss: 0.4577, acc: 0.8135
loss: 0.4586, acc: 0.8136
loss: 0.4582, acc: 0.8139
loss: 0.4582, acc: 0.8150
loss: 0.4581, acc: 0.8150
loss: 0.4591, acc: 0.8142
loss: 0.4610, acc: 0.8131
loss: 0.4607, acc: 0.8135
loss: 0.4590, acc: 0.8148
loss: 0.4583, acc: 0.8145
loss: 0.4605, acc: 0.8142
loss: 0.4611, acc: 0.8144
loss: 0.4604, acc: 0.8143
loss: 0.4609, acc: 0.8133
loss: 0.4615, acc: 0.8131
> val_acc: 0.6812, val_f1: 0.5758
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.3083, acc: 0.8958
loss: 0.3057, acc: 0.8965
loss: 0.3013, acc: 0.8942
loss: 0.2990, acc: 0.8915
loss: 0.2945, acc: 0.8906
loss: 0.2965, acc: 0.8884
loss: 0.3027, acc: 0.8868
loss: 0.3176, acc: 0.8799
loss: 0.3191, acc: 0.8790
loss: 0.3219, acc: 0.8766
loss: 0.3249, acc: 0.8759
loss: 0.3278, acc: 0.8750
loss: 0.3295, acc: 0.8740
loss: 0.3340, acc: 0.8718
loss: 0.3362, acc: 0.8703
loss: 0.3325, acc: 0.8714
loss: 0.3311, acc: 0.8718
loss: 0.3300, acc: 0.8711
loss: 0.3318, acc: 0.8696
loss: 0.3357, acc: 0.8673
loss: 0.3358, acc: 0.8668
loss: 0.3389, acc: 0.8653
loss: 0.3403, acc: 0.8641
loss: 0.3418, acc: 0.8643
loss: 0.3426, acc: 0.8632
loss: 0.3472, acc: 0.8619
loss: 0.3491, acc: 0.8609
loss: 0.3498, acc: 0.8595
loss: 0.3510, acc: 0.8590
loss: 0.3520, acc: 0.8584
loss: 0.3548, acc: 0.8571
loss: 0.3551, acc: 0.8567
loss: 0.3570, acc: 0.8553
loss: 0.3577, acc: 0.8543
loss: 0.3608, acc: 0.8530
loss: 0.3615, acc: 0.8526
loss: 0.3642, acc: 0.8521
loss: 0.3666, acc: 0.8514
loss: 0.3670, acc: 0.8512
> val_acc: 0.6748, val_f1: 0.5700
